#!/usr/bin/env python
# -*- coding: utf-8 -*-

'''
Faraday Penetration Test IDE - Community Version
Copyright (C) 2013  Infobyte LLC (http://www.infobytesec.com/)
See the file 'doc/LICENSE' for the license information

'''
from __future__ import with_statement
from plugins import core
from model import api
import re
import os
import pprint
import sys
import json
import socket
import random



current_path = os.path.abspath(os.getcwd())

__author__     = "Nicolas Rodriguez"
__copyright__  = "Copyright (c) 2013, Infobyte LLC"
__credits__    = ["Nicolas Rodriguez"]
__license__    = ""
__version__    = "1.0.0"
__maintainer__ = "Francisco Amato"
__email__      = "famato@infobytesec.com"
__status__     = "Development"


class SkipfishParser(object):
    """
    The objective of this class is to parse an xml file generated by the skipfish tool.

    TODO: Handle errors.
    TODO: Test skipfish output version. Handle what happens if the parser doesn't support it.
    TODO: Test cases.

    @param skipfish_filepath A proper xml generated by skipfish
    """
    def __init__(self, skipfish_filepath):
        self.filepath = skipfish_filepath
        
        tmp = open(skipfish_filepath+"/samples.js", "r").read()
        issues = json.loads(self.extract_data(tmp, "var issue_samples =", "];",
                    lambda x: x.replace("'", '"'), False, False)[1] + "]")
        
        tmp = open(skipfish_filepath+"/index.html", "r").read()
        err_msg = json.loads(self.extract_data(tmp, "var issue_desc=", "};",
                    lambda x: self.convert_quotes(x, "'", '"'), False, False)[1] + "}")
        
        self.err_msg=err_msg
        self.issues=issues

    def convert_quotes(self,text, quote="'", inside='"'):
        start = 0
        while True:
            pos = text.find(quote, start)
    
            if pos == -1:
                break
    
            ss = text[:pos - 1]
            quotes = len(ss) - len(ss.replace(inside, ""))
    
            if quotes % 2 == 0:
                text = text[:pos - 1] + "\\" + quote + text[pos + 1:]
    
            start = pos + 1
        return text
    
    def extract_data(self, samples, start_tag, end_tag, fn=lambda x: x, include_start_tag=True, include_end_tag=True):
        start = samples.find(start_tag)
    
        if start == -1:
            return (-1, None)
    
        end = samples.find(end_tag, start + 1)
    
        if end == -1:
            return (-2, None)
    
        data = samples[start:end + len(end_tag)]
        data = fn(data)
    
        if not include_start_tag:
            data = data[len(start_tag) + 1:]
    
        if not include_end_tag:
            data = data[:-1 * len(end_tag)]
    
        return (0, data)


class SkipfishPlugin(core.PluginBase):
    """
    Example plugin to parse skipfish output.
    """
    def __init__(self):
        core.PluginBase.__init__(self)
        self.id              = "Skipfish"
        self.name            = "Skipfish XML Output Plugin"
        self.plugin_version         = "0.0.2"
        self.version   = "2.1.5"
        self.options         = None
        self._current_output = None
        self.parent = None
        self._command_regex  = re.compile(r'^(sudo skipfish|skipfish|sudo skipfish\.pl|skipfish\.pl|perl skipfish\.pl|\.\/skipfish\.pl|\.\/skipfish).*?')
        self._completition = {
                                "":"Usage: skipfish [ options ... ] -W wordlist -o output_dir start_url [ start_url2 ... ]",
                                "-A":"user:pass - use specified HTTP authentication credentials",
                                "-F":"host=IP - pretend that 'host' resolves to 'IP'",
                                "-C":"name=val - append a custom cookie to all requests",
                                "-H":"name=val - append a custom HTTP header to all requests",
                                "-b":"(i|f|p) - use headers consistent with MSIE / Firefox / iPhone",
                                "-N":"- do not accept any new cookies",
                                "--auth-form":"url - form authentication URL",
                                "--auth-user":"user - form authentication user",
                                "--auth-pass":"pass - form authentication password",
                                "--auth-verify-url":" --auth-verify-url -  URL for in-session detection",
                                "-d":"max_depth - maximum crawl tree depth (16)",
                                "-c":"max_child - maximum children to index per node (512)",
                                "-x":"max_desc - maximum descendants to index per branch (8192)",
                                "-r":"r_limit - max total number of requests to send (100000000)",
                                "-p":"crawl% - node and link crawl probability (100%)",
                                "-q":"hex - repeat probabilistic scan with given seed",
                                "-I":"string - only follow URLs matching 'string'",
                                "-X":"string - exclude URLs matching 'string'",
                                "-K":"string - do not fuzz parameters named 'string'",
                                "-D":"domain - crawl cross-site links to another domain",
                                "-B":"domain - trust, but do not crawl, another domain",
                                "-Z":"- do not descend into 5xx locations",
                                "-O":"- do not submit any forms",
                                "-P":"- do not parse HTML, etc, to find new links",
                                "-o":"dir - write output to specified directory (required)",
                                "-M":"- log warnings about mixed content / non-SSL passwords",
                                "-E":"- log all HTTP/1.0 / HTTP/1.1 caching intent mismatches",
                                "-U":"- log all external URLs and e-mails seen",
                                "-Q":"- completely suppress duplicate nodes in reports",
                                "-u":"- be quiet, disable realtime progress stats",
                                "-v":"- enable runtime logging (to stderr)",
                                "-W":"wordlist - use a specified read-write wordlist (required)",
                                "-S":"wordlist - load a supplemental read-only wordlist",
                                "-L":"- do not auto-learn new keywords for the site",
                                "-Y":"- do not fuzz extensions in directory brute-force",
                                "-R":"age - purge words hit more than 'age' scans ago",
                                "-T":"name=val - add new form auto-fill rule",
                                "-G":"max_guess - maximum number of keyword guesses to keep (256)",
                                "-z":"sigfile - load signatures from this file",
                                "-g":"max_conn - max simultaneous TCP connections, global (40)",
                                "-m":"host_conn - max simultaneous connections, per target IP (10)",
                                "-f":"max_fail - max number of consecutive HTTP errors (100)",
                                "-t":"req_tmout - total request response timeout (20 s)",
                                "-w":"rw_tmout - individual network I/O timeout (10 s)",
                                "-i":"idle_tmout - timeout on idle HTTP connections (10 s)",
                                "-s":"s_limit - response size limit (400000 B)",
                                "-e":"- do not keep binary responses for reporting",
                                "-l":"max_req - max requests per second (0.000000)",
                                "-k":"duration - stop scanning after the given duration h:m:s",
                                "--config":"- load the specified configuration file",

        }

        global current_path


    def parseOutputString(self, output, debug = False ):
        """
        This method will discard the output the shell sends, it will read it from
        the xml where it expects it to be present.

        NOTE: if 'debug' is true then it is being run from a test case and the
        output being sent is valid.
        """
                                                              
        if (re.search("\r\n",output) is None):
            self._output_path=output
            
        if not os.path.exists(self._output_path):
            return False
        
        p = SkipfishParser(self._output_path)

        hostc={}
        port=80
        for issue in p.issues:
            request=""
            response=""
            for sample in issue["samples"]:
                if not sample["url"] in hostc:
                    reg = re.search("(http|https|ftp)\://([a-zA-Z0-9\.\-]+(\:[a-zA-Z0-9\.&amp;%\$\-]+)*@)*((25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[1-9])\.(25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[1-9]|0)\.(25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[1-9]|0)\.(25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[0-9])|localhost|([a-zA-Z0-9\-]+\.)*[a-zA-Z0-9\-]+\.(com|edu|gov|int|mil|net|org|biz|arpa|info|name|pro|aero|coop|museum|[a-zA-Z]{2}))[\:]*([0-9]+)*([/]*($|[a-zA-Z0-9\.\,\?\'\\\+&amp;%\$#\=~_\-]+)).*?$", sample["url"])
                                        
                    protocol = reg.group(1)
                    host = reg.group(4)
                    if reg.group(11) is not None:
                        port = reg.group(11)
                    else:
                        port = 443 if protocol == "https" else 80
                        
                    ip = self.resolve(host)
        
                    h_id = self.createAndAddHost(ip)
                    i_id = self.createAndAddInterface(h_id, ip, ipv4_address=ip,hostname_resolution=host)
                    s_id = self.createAndAddServiceToInterface(h_id, i_id, "http",
                                                       "tcp",
                                                       ports = [port],
                                                       status = "open")
    
                    n_id = self.createAndAddNoteToService(h_id,s_id,"website","")
                    n2_id = self.createAndAddNoteToNote(h_id,s_id,n_id,host,"")
    

                    hostc[sample["url"]]={'h_id':h_id, 'ip':ip,'port':port,'host':host,'protocol':protocol,
                           'i_id':i_id,'s_id':s_id}
                        
            
                try:
                    request =open("%s/request.dat" % sample["dir"], "r").read()
                except:
                    pass
                
                try:
                    response =open("%s/request.dat" % sample["dir"], "r").read()
                except:
                    pass
        
                d=hostc[sample["url"]]
                v_id = self.createAndAddVulnWebToService(d['h_id'], d['s_id'],
                                                     name=p.err_msg[str(issue["type"])],desc="Extra: " + sample["extra"], website=d['host'],
                                                     path=sample["url"],severity=issue["severity"])


    def resolve(self, host):
        try:
            return socket.gethostbyname(host)
        except:
            pass
        return host

    xml_arg_re = re.compile(r"^.*(-o\s*[^\s]+).*$")

    def processCommandString(self, username, current_path, command_string):
        """
        Adds the -o parameter to get report of the command string that the
        user has set.
        """
        arg_match = self.xml_arg_re.match(command_string)

        self._output_path = os.path.join(self.data_path,
                                             "skipfish_output-%s" % random.uniform(1,10))

        if arg_match is None:
            return re.sub(r"(^.*?skipfish)",
                          r"\1 -o %s" % self._output_path,
                          command_string,1)
        else:
            return re.sub(arg_match.group(1),
                          r"-o %s" % self._output_path,
                          command_string,1)

    def setHost(self):
        pass


def createPlugin():
    return SkipfishPlugin()

if __name__ == '__main__':
    parser = SkipfishParser(sys.argv[1])
    for item in parser.items:
        if item.status == 'up':
            print item
